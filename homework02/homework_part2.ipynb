{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Artem Moskalev. Homework 2.2: The Quest For A Better Network\n",
    "\n",
    "In this assignment you will:\n",
    "\n",
    "    1. Build a monster network to solve CIFAR10 image classification\n",
    "    2. Apply your transfer learning skills to fine-tune your network to a restricted CIFAR100 dataset.\n",
    "\n",
    "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    "\n",
    "We add a new task of fine-tuning a pretrained network for different classes of similar domain. After you obtain good results on CIFAR-10 dataset:\n",
    "\n",
    "* choose any two classes from CIFAR-100\n",
    "* change your trained network to be suitable for binary classification\n",
    "* fine-tune it for reasonably good results on 2 classes from CIFAR-100\n",
    "* repeat the same for random initialization of the same network\n",
    "* compare the performance and training time in your report\n",
    "\n",
    "\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +20% for describing your iteration path in a report below.\n",
    "* +20% for building a network that gets above 20% accuracy\n",
    "* +5% for beating each of these milestones on __TEST__ dataset:\n",
    "    * 50% (45% points)\n",
    "    * 60% (50% points)\n",
    "    * 65% (55% points)\n",
    "    * 70% (60% points)\n",
    "    * 75% (65% points)\n",
    "    * 80% (70% points)\n",
    "* +30% for fine-tuning your best CIFAR-10 network for two classes from CIFAR-100, comparing the results with training the same network from scratch and reporting the results\n",
    "\n",
    "    \n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 80%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the e-mail). After that, you can use whatever you want.\n",
    "* you __can__ use validation data for training, but you __can't'__ do anything with test data apart from running the evaluation procedure.\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    " * __Network architecture__\n",
    "   * Different ways to combine convolutional/pooling/activation layers\n",
    "   * Regularization methods\n",
    "\n",
    "\n",
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Try different optimizers, especially Adam, RMSProp, Adagrad, SGD with momentum: ([torch.optim](http://pytorch.org/docs/0.3.1/optim.html))\n",
    "   * Sometimes it makes sense to reduce LR during training: ([Dynamic learning rates](http://pytorch.org/docs/0.3.1/optim.html#how-to-adjust-learning-rate))\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recommend that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.CIFAR10(root=path_to_cifar_like_in_seminar, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "   \n",
    "There is a template for your solution below that you can opt to use or throw away and write it your way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 3, 32, 32) (40000,)\n"
     ]
    }
   ],
   "source": [
    "from cifar import load_cifar10, load_cifar100\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_cifar10(\"cifar_data\")\n",
    "class_names = np.array(['airplane','automobile ','bird ','cat ','deer ','dog ','frog ','horse ','ship ','truck'])\n",
    "\n",
    "print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 3, 32, 32) (800,)\n",
      "(200, 3, 32, 32) (200,)\n",
      "(200, 3, 32, 32) (200,)\n"
     ]
    }
   ],
   "source": [
    "X_train100, y_train100, X_val100, y_val100, X_test100, y_test100 = load_cifar100('./cifar100/', \n",
    "                                                                                 target_classes=(13, 37))\n",
    "print(X_train100.shape, y_train100.shape)\n",
    "print(X_val100.shape, y_val100.shape)\n",
    "print(X_test100.shape, y_test100.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ##### Augment CIFAR10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "\n",
    "def augment_rotation(X,dummy=None):\n",
    "    return np.flip(X, axis=3)\n",
    "\n",
    "def augment_crop(X, size=22): #assume images are squares\n",
    "    d = X.shape[2] - size\n",
    "    dx = np.random.randint(X.shape[1]-d, X.shape[1])\n",
    "    dy = np.random.randint(X.shape[2]-d, X.shape[2])\n",
    "    cropped = X[:,(dx-size):dx,(dy-size):dy].copy()\n",
    "    return resize(cropped, output_shape=X.shape, mode='reflect')\n",
    "\n",
    "def augment_dataset(X_data, y_data, n=2):\n",
    "    rotated = np.apply_over_axes(func=augment_rotation, a=X_data, axes=[0])\n",
    "    print('Rotation done')\n",
    "    \n",
    "    X_cropped, y_cropped = list(), list()\n",
    "    for i in tqdm_notebook(range(0,X_data.shape[0],n)):\n",
    "        X_cropped.append(augment_crop(X_data[i]))\n",
    "        y_cropped.append(y_data[i])\n",
    "    \n",
    "    X_cropped, y_cropped = np.array(X_cropped), np.array(y_cropped)\n",
    "    \n",
    "    augmented_X = np.concatenate((X_data,rotated,X_cropped))\n",
    "    augmented_y = np.concatenate((y_data,y_data,y_cropped))\n",
    "    \n",
    "    return augmented_X, augmented_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAElCAYAAACVuhGbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNMz/D4D0PWEo8PodAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f502c219a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img1 = X_train[3].copy()\n",
    "rot1 = augment_rotation(img1.reshape(1,3,32,32))[0,...]\n",
    "cr1 = augment_crop(img1, size=20)\n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15,7))\n",
    "ax[0].imshow(img1[0,...], cmap='gray')\n",
    "ax[0].set_title('Original')\n",
    "ax[1].imshow(rot1[0,...], cmap='gray')\n",
    "ax[1].set_title('Flipped')\n",
    "ax[2].imshow(cr1[0,...], cmap='gray')\n",
    "ax[2].set_title('Cropped');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ed2119f2694612b8a57a689021fd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_aug, y_train_aug = augment_dataset(X_train, y_train, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ##### CIFAR10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        #print(input.size())\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "model.add_module('Conv1', nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, padding=1))\n",
    "model.add_module('Conv1-2', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1))\n",
    "model.add_module('bn1', nn.BatchNorm2d(256))\n",
    "model.add_module('relu1', nn.LeakyReLU())\n",
    "model.add_module('mp1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "model.add_module('Conv2', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1))\n",
    "model.add_module('bn2', nn.BatchNorm2d(512))\n",
    "model.add_module('relu2', nn.LeakyReLU())\n",
    "model.add_module('mp2', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "model.add_module('Conv3', nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1))\n",
    "model.add_module('bn3', nn.BatchNorm2d(1024))\n",
    "model.add_module('relu3', nn.LeakyReLU())\n",
    "\n",
    "model.add_module('av1', nn.AvgPool2d(kernel_size=8))\n",
    "model.add_module('flatten', Flatten())\n",
    "model.add_module('fc1', nn.LeakyReLU())\n",
    "\n",
    "model.add_module('Lin', nn.Linear(1024, 10))\n",
    "model.add_module('SM', nn.Softmax(dim=1))\n",
    "\n",
    "model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch).cuda())\n",
    "    y_batch = Variable(torch.LongTensor(y_batch).cuda())\n",
    "    logits = model(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Training __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(X, y, batchsize):\n",
    "    indices = np.random.permutation(np.arange(len(X)))\n",
    "    for start in range(0, len(indices), batchsize):\n",
    "        ix = indices[start: start + batchsize]\n",
    "        yield X[ix], y[ix]\n",
    "        \n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93dd1c785054d45bb3dac2bc9a3dc88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 25 took 329.111s\n",
      "  training loss (in-iteration): \t2.001197\n",
      "  validation accuracy: \t\t\t46.06 %\n",
      "Epoch 2 of 25 took 323.498s\n",
      "  training loss (in-iteration): \t1.880091\n",
      "  validation accuracy: \t\t\t61.97 %\n",
      "Epoch 3 of 25 took 323.449s\n",
      "  training loss (in-iteration): \t1.823942\n",
      "  validation accuracy: \t\t\t63.81 %\n",
      "Epoch 4 of 25 took 323.420s\n",
      "  training loss (in-iteration): \t1.783672\n",
      "  validation accuracy: \t\t\t66.98 %\n",
      "Epoch 5 of 25 took 323.510s\n",
      "  training loss (in-iteration): \t1.744280\n",
      "  validation accuracy: \t\t\t67.31 %\n",
      "Epoch 6 of 25 took 323.389s\n",
      "  training loss (in-iteration): \t1.723009\n",
      "  validation accuracy: \t\t\t67.71 %\n",
      "Epoch 7 of 25 took 323.443s\n",
      "  training loss (in-iteration): \t1.695531\n",
      "  validation accuracy: \t\t\t73.34 %\n",
      "Epoch 8 of 25 took 323.418s\n",
      "  training loss (in-iteration): \t1.652580\n",
      "  validation accuracy: \t\t\t81.06 %\n",
      "Epoch 9 of 25 took 323.533s\n",
      "  training loss (in-iteration): \t1.637576\n",
      "  validation accuracy: \t\t\t81.15 %\n",
      "Epoch 10 of 25 took 323.568s\n",
      "  training loss (in-iteration): \t1.622064\n",
      "  validation accuracy: \t\t\t81.35 %\n",
      "Epoch 11 of 25 took 323.591s\n",
      "  training loss (in-iteration): \t1.611894\n",
      "  validation accuracy: \t\t\t81.49 %\n",
      "Epoch 12 of 25 took 323.621s\n",
      "  training loss (in-iteration): \t1.600077\n",
      "  validation accuracy: \t\t\t81.66 %\n",
      "Epoch 13 of 25 took 323.638s\n",
      "  training loss (in-iteration): \t1.590328\n",
      "  validation accuracy: \t\t\t82.54 %\n",
      "Epoch 14 of 25 took 323.550s\n",
      "  training loss (in-iteration): \t1.582846\n",
      "  validation accuracy: \t\t\t82.75 %\n",
      "Epoch 15 of 25 took 323.321s\n",
      "  training loss (in-iteration): \t1.556836\n",
      "  validation accuracy: \t\t\t85.23 %\n",
      "Epoch 16 of 25 took 323.345s\n",
      "  training loss (in-iteration): \t1.555295\n",
      "  validation accuracy: \t\t\t85.65 %\n",
      "Epoch 17 of 25 took 323.562s\n",
      "  training loss (in-iteration): \t1.544123\n",
      "  validation accuracy: \t\t\t85.62 %\n",
      "Epoch 18 of 25 took 323.480s\n",
      "  training loss (in-iteration): \t1.543841\n",
      "  validation accuracy: \t\t\t85.50 %\n",
      "Epoch 19 of 25 took 323.454s\n",
      "  training loss (in-iteration): \t1.537566\n",
      "  validation accuracy: \t\t\t85.40 %\n",
      "Epoch 20 of 25 took 323.429s\n",
      "  training loss (in-iteration): \t1.531387\n",
      "  validation accuracy: \t\t\t85.37 %\n",
      "Epoch 21 of 25 took 323.469s\n",
      "  training loss (in-iteration): \t1.529646\n",
      "  validation accuracy: \t\t\t85.48 %\n",
      "Epoch 22 of 25 took 323.439s\n",
      "  training loss (in-iteration): \t1.516395\n",
      "  validation accuracy: \t\t\t86.28 %\n",
      "Epoch 23 of 25 took 323.452s\n",
      "  training loss (in-iteration): \t1.515760\n",
      "  validation accuracy: \t\t\t86.40 %\n",
      "Epoch 24 of 25 took 323.406s\n",
      "  training loss (in-iteration): \t1.514668\n",
      "  validation accuracy: \t\t\t86.21 %\n",
      "Epoch 25 of 25 took 323.420s\n",
      "  training loss (in-iteration): \t1.513089\n",
      "  validation accuracy: \t\t\t86.34 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_epochs = 25 # total amount of full passes over training data\n",
    "batch_size = 128  # number of samples processed in one SGD iteration\n",
    "\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    start_time = time.time()\n",
    "    model.train(True) # enable dropout / batch_norm training behavior\n",
    "    for X_batch, y_batch in iterate_minibatches(X_train_aug, y_train_aug, batch_size):\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "        \n",
    "    if (epoch+1)%7==0 and (epoch+1)<=18:\n",
    "        opt.param_groups[0]['lr'] = opt.param_groups[0]['lr']/2\n",
    "    elif (epoch+1)%3==0 and (epoch+1)>18:\n",
    "        opt.param_groups[0]['lr'] = opt.param_groups[0]['lr']/10\n",
    "    \n",
    "    # And a full pass over the validation data:\n",
    "    model.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        logits = model(Variable(torch.FloatTensor(X_batch).cuda()))\n",
    "        y_pred = logits.max(1)[1].cpu().data.numpy()\n",
    "        val_accuracy.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t85.57 %\n",
      "Achievement unlocked: 110lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "model.train(False) # disable dropout / use averages for batch_norm\n",
    "test_batch_acc = []\n",
    "for X_batch, y_batch in iterate_minibatches(X_test, y_test, 100):\n",
    "    logits = model(Variable(torch.FloatTensor(X_batch).cuda()))\n",
    "    y_pred = logits.cpu().max(1)[1].data.numpy()\n",
    "    test_batch_acc.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "test_accuracy = np.mean(test_batch_acc)\n",
    "    \n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 95:\n",
    "    print(\"Double-check, than consider applying for NIPS'18. SRSly.\")\n",
    "elif test_accuracy * 100 > 90:\n",
    "    print(\"U'r freakin' amazin'!\")\n",
    "elif test_accuracy * 100 > 80:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 70:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 60:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 50:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check what is accuracy on the train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  Train accuracy:\t\t96.43 %\n",
      "Double-check, than consider applying for NIPS'18. SRSly.\n"
     ]
    }
   ],
   "source": [
    "model.train(False) # disable dropout / use averages for batch_norm\n",
    "test_batch_acc = []\n",
    "for X_batch, y_batch in iterate_minibatches(X_train, y_train, 100):\n",
    "    logits = model(Variable(torch.FloatTensor(X_batch).cuda()))\n",
    "    y_pred = logits.cpu().max(1)[1].data.numpy()\n",
    "    test_batch_acc.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "test_accuracy = np.mean(test_batch_acc)\n",
    "    \n",
    "print(\"Final results:\")\n",
    "print(\"  Train accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 95:\n",
    "    print(\"Double-check, than consider applying for NIPS'18. SRSly.\")\n",
    "elif test_accuracy * 100 > 90:\n",
    "    print(\"U'r freakin' amazin'!\")\n",
    "elif test_accuracy * 100 > 80:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 70:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 60:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 50:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That beacause I test an accaracy on non augmented training set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save weights to use it in our new model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers, weights, biases = ['Conv1','Conv1-2','bn1','Conv2','bn2','Conv3','bn3'], dict(), dict()\n",
    "\n",
    "weights['Conv1'] = model.Conv1.weight\n",
    "biases['Conv1'] = model.Conv1.bias\n",
    "\n",
    "weights['Conv1-2'] = model.__dict__['_modules']['Conv1-2'].weight\n",
    "biases['Conv1-2'] = model.__dict__['_modules']['Conv1-2'].bias\n",
    "\n",
    "weights['bn1'] = model.bn1.weight\n",
    "biases['bn1'] = model.bn1.bias\n",
    "\n",
    "weights['Conv2'] = model.Conv2.weight\n",
    "biases['Conv2'] = model.Conv2.bias\n",
    "\n",
    "weights['bn2'] = model.bn2.weight\n",
    "biases['bn2'] = model.bn2.bias\n",
    "\n",
    "weights['Conv3'] = model.Conv3.weight\n",
    "biases['Conv3'] = model.Conv3.bias\n",
    "\n",
    "weights['bn3'] = model.bn3.weight\n",
    "biases['bn3'] = model.bn3.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ##### CIFAR100:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Select two classes from CIFAR100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train100[y_train100==13] = 0.\n",
    "y_train100[y_train100==37] = 1.\n",
    "\n",
    "y_test100[y_test100==13] = 0.\n",
    "y_test100[y_test100==37] = 1.\n",
    "\n",
    "y_val100[y_val100==13] = 0.\n",
    "y_val100[y_val100==37] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlMAAAEtCAYAAAAsgeXEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XtsnNd95vHn6EKKN4kSdaMoWpJl\nWVAsOEqsBEmTpomTeLNpiqRAN2iDBN4iqItuAmyL7h9BtthmF/2jXWwbFOiiC2cTxGmzSb2t3QS7\nbhLHtWvUcW3Lji1ZlhxdfJFE6kpRpChSoqizf3C0UGzN76F4Zjgj+fsBBFHz8J058877njkazjxM\nOWcBAABgduY1egAAAADXMxZTAAAABVhMAQAAFGAxBQAAUIDFFAAAQAEWUwAAAAVYTAEAABRgMYW6\nSSl9MaW0I6V0PqX0zUaPBwCuRUppWUrpwZTSWErptZTSZxo9JjSnBY0eAG5oA5L+SNK/ktTW4LEA\nwLX675IuSFolaZuk/5tSeiHnvLuxw0KzSTSgo95SSn8kaW3O+d82eiwAMBMppQ5JpyVtzTn/rHLZ\nX0k6knP+UkMHh6bDj/kAAHizWyVNXV5IVbwg6bYGjQdNjMUUAABv1inpzBsuOyOpqwFjQZNjMQUA\nwJudlbT4DZctljTagLGgybGYAgDgzX4maUFKadMVl71dEm8+x5uwmELdpJQWpJQWSZovaX5KaVFK\niU+QAmh6OecxSQ9I+i8ppY6U0vskfVLSXzV2ZGhGLKZQT38gaVzSlyR9tvL1HzR0RAAwc/9O07Uu\nxyV9R9LvUIuAq6EaAQAAoACvTAEAABRgMQUAAFCAxRQAAEABFlMAAAAFWEwBAAAUKOr8SSl9TNKf\na7pH6H/mnP84+v5ly5bl/v7+qvmlS5fC2yv95GG9P7mYUqqazZsXr1tdPn/+/Fnf9ky4fXPx4sUw\nP3/+fNHtL1y4MMwnJibCfHx8vGh7t3/d/Y/y0seu9LF1j83k5GTR9bt9MzU1dTLnvKLoRurkWuaw\n9vb2vGTJkpLbmvW2tdge9VPv+bdUyfWXjq3e+8atG0qv/8SJEzOav2a9mEopzZf03yV9VNJhSc+k\nlL6fc36p2jb9/f36h3/4h6rX6Z7w3KQ/NTUV5m7Sd9xBET1pdnR0hNt2dcW/7qm9vT3MFy1aFObu\ngLtw4UKYDw0NhfnBgweLbr+3tzfM9+7dG+YvvVT1sJMkvfzyy2He3d0d5idOnAjzU6dOVc3cY9vS\n0hLmCxbEp6k7Lt1jc/To0TB359XJkyfDfHh4+LXwGxrkWuewJUuW6Dd/8zdnfXtuUV36ONdzsVV6\n3aVPeKX33f1ntVTp9Zc+N5UuOKJz3I3N3bY7rt2+c/8ZdM9dJfddkv7iL/5iRvNXyRHwbkn7c84H\nc84XJH1X0+2wAHA9YA4DUBMli6k+SYeu+PfhymUAcD1gDgNQEyWLqau9rvqm1/tSSveklHaklHZE\nPwoBgDlm57Ar569z587N0bAAXG9KFlOHJV35bvK1kgbe+E0553tzzttzztt7enoKbg4AasrOYVfO\nX+59iwDeukoWU89I2pRS2pBSapH065K+X5thAUDdMYcBqIlZf5ov53wxpfRFST/U9MeKv8Fv0wZw\nvWAOA1ArRT1TOeeHJD10Dd8ffkzRfXTYfYTSVSe4j8+WfgQ0+oimu273fgz38dLW1tYwdx//dO9n\nGx4eLsrdx1ddPYCrfnAfz3fXv3Tp0jB3j09UL+D2zZkzZ8J88eLFYe5+fO6qD1zHl8tXr14d5u7+\nN9K1zGHz5s2zx6HbvoSbA+qp0T1KpdUI9e7ocvfP5e4cK+0BdM+tUe6OO/fc4m7bcY9dabWMG/9M\n0YAOAABQgMUUAABAARZTAAAABVhMAQAAFGAxBQAAUIDFFAAAQAEWUwAAAAXmvLgk6sNwXRqur8J1\nLbm+CddTFXVkudz1gJw/fz7Mx8fHw9z1LLntJyYmwnxkZCTMz549G+Zu3w8MvOk3Ef2cNWvWhPkv\n/dIvhfkzzzwT5keOHAlz1y/U399fNXP7rqOjI8xdx5U7tnp7e8Pc9Vjt3h33WHZ2dob5jaSkK8qd\nA/XuSirZvnRs9e6ZajR3Djruua2k41Dyx21pB1rE7Rv3vFrKXX/psXkZr0wBAAAUYDEFAABQgMUU\nAABAARZTAAAABVhMAQAAFGAxBQAAUIDFFAAAQIE57ZnKOYedDq4rw3WNuK6OhQsXhnlJj9RM8ojr\nunBdQ66namxsLMxdT5Xb966HqaWlJcxdF8ng4GCYr1ixIsx/5Vd+Jcwfe+yxMD906FCYr127tmrm\n9p27b8PDw2Hu9t3q1avDvLTHyh07N5Koj8d19bj5qZ5dP6XXX9ozVXrf3L6bmpoK83p3GZX2OJU+\nN7nnD3f9JY+Pe9523Nhd7h770dHRMC/tCLuMV6YAAAAKsJgCAAAowGIKAACgAIspAACAAiymAAAA\nCrCYAgAAKMBiCgAAoMCc9kyllGwfScT1TZT2Rbixua6kqKtjfHw83NZ1YYyMjIT5xMRE0fb17pFy\n1+96UNxjPzQ0FOadnZ1h/sEPfjDM9+/fH+Y//OEPq2au48t1yLz88sth7nqknNbW1jBfunRpmB89\nerTo9q8X8+bNs8d5pNE9UyVdUSXztlR+393578bnuohKld4/dw66466npyfM3fii+d3dtuuZOnXq\nVJgfPHgwzG+99dYwd8+dbn51288Ur0wBAAAUYDEFAABQgMUUAABAARZTAAAABVhMAQAAFGAxBQAA\nUIDFFAAAQIGinqmU0quSRiVNSbqYc97uton6NlyfheuLcPnk5GSYuy6Otra2MI96roaHh8NtXdfF\nyZMnw/z8+fNh7npMXA/KggXxoeJy1/Pixu96Ztz4S/f/li1bwjzqYvrxj38cbut6pNx5ceLEiTB3\nj43bt8ePHy+6/mZ2LXNYSsn2oUXc/OJyxz2Obn6MziF3frmep+XLl4f5mjVrwtx1GR07dizMXc+e\n2/fucXfPDaXzq9t/K1asCHP3+LS3t1fN3HOH63f89re/HeYPP/xwmG/evDnM3fO660islVrMgh/K\nOcfP9ADQvJjDABThx3wAAAAFShdTWdKPUkrPppTuqcWAAGAOMYcBKFb6Y7735ZwHUkorJT2cUtqb\nc378ym+oTFD3SFJfX1/hzQFATYVz2JXzl/sdhQDeuopemco5D1T+Pi7pQUnvvsr33Jtz3p5z3r5s\n2bKSmwOAmnJz2JXzl/tl2QDeuma9mEopdaSUui5/LekuSS/WamAAUE/MYQBqpeTHfKskPVj5yOUC\nSf8r5/yDmowKAOqPOQxATcx6MZVzPijp7deyTUqpqJPGdXXM5PYjrgvJ9fkMDQ1Vzc6ePRtue/r0\n6TB3XR4dHR1h7nqWfvKTn4T5rbfeGuauC8mN7+jRo2Hueqicu+66K8zPnTsX5vv37w/zlStXVs0+\n/elPh9s+/vjjYf7UU0+FuTu2Vq9eHeauYyu6b5LvyDl8+HCYN8ps5rBoDnLziztH3PzmeqJcz1RJ\nz5Ubm+th2rRpU5ivX78+zN38cfDgwTB3x6DrInI/4l28eHGY79u3L8wHBwfD3O2ftWvXhrk7dqLH\n3h03Bw4cCHPXo+eeV48cORLmGzduDHPXMeaee2aKagQAAIACLKYAAAAKsJgCAAAowGIKAACgAIsp\nAACAAiymAAAACrCYAgAAKFD6u/muieuZKunCkKQLFy6E+euvv150/a6LKOqZcl0+rselvb09zF1P\nSjQ2STp16lSYux4s1wPT1tYW5pOTk2HuupTGx8fD3HUAuZ4cd2xGXSmug+bDH/5wmPf09IT5v/zL\nv4S561F57bXXwnxiYiLM3WN3o8g5h110bv5wx5DrknPX747x1tbWMI/OUdcl5s5/t/2ZM2eKtne/\n97W3tzfM621gYCDMXY+Ve2zdc5MTPXeOjY2F2+7duzfM3fzinhvcc6PLXY+V6xCcKV6ZAgAAKMBi\nCgAAoACLKQAAgAIspgAAAAqwmAIAACjAYgoAAKDAnFYjSPHHGN1Hf91HIHfv3h3mx48fD/Ply5eH\nuasHOH/+fNXMfbTXfWzZbe8+2u9yt29feumlMF+yZEmYRx8pl6QnnngizDds2BDmjvtosctLjs2R\nkZFwW1frsGXLljBfv359mH/1q18Ncze+lStXhvmePXvC/EZx6dKlsKLDnWNuPzruI+SuWsHdfvTx\nfFfv4a7bbe/G7mpvHHd+u+qakydPhrkb3+HDh8P8lVdeCfNdu3aF+bZt28Lc1RtEt++qVVw1yr59\n+8LcnTfuuc/l0fOyJP3kJz8J85nilSkAAIACLKYAAAAKsJgCAAAowGIKAACgAIspAACAAiymAAAA\nCrCYAgAAKDCnPVMppbCvx3V1nDhxouj2XdeJ66FyfRWLFi2qmrW3t4fbuh4j15PiuB4p12HT6O07\nOjrC3PVYXbp0KcxzzmHuRI+P61FxYxsYGAjznp6eMP/CF74Q5g8//HCY/+AHPwjzt4r58+eHfWru\nGFyzZk2YL126NMyj+UXyfTtdXV1hHs1v7vx1c7frGnJdRm7uP3bsWFHuzv8XXnghzDdv3hzmTz/9\ndJgfPHgwzLu7u8N87969Yb5z584wHx4erpq547Kvry/Mz507F+Zu33/rW98K8w996ENh7s5Ld97M\nFK9MAQAAFGAxBQAAUIDFFAAAQAEWUwAAAAVYTAEAABRgMQUAAFCAxRQAAEABW7CQUvqGpE9IOp5z\n3lq5bJmkv5G0XtKrkj6dcz49kxuM+nhcl4jrIhkfHw/zwcHBMHdc11HUA1PaE+W6iFzPi+vYuuuu\nu8I86teRfFeH69G64447wtzdv4mJiTB3x4bbv65nx+WR0mPDnReu4+wzn/lMmN9yyy1hfu+994b5\nc889F+b1Vqs5bNGiRWGfkNvPrkutpaUlzEdHR8Pc9fm47aP5123rzq8DBw6EuTt/XU+Uu3333HLT\nTTeF+ZNPPhnm7rF/7bXXwtyNz83f7tiZnJwM88iyZcvCvL+/P8xdR5frb3z99dfD/P777w9zd99d\n/9tMzeQZ4JuSPvaGy74k6ZGc8yZJj1T+DQDN6JtiDgNQR3YxlXN+XNLQGy7+pKT7Kl/fJ+lTNR4X\nANQEcxiAepvtzyZW5ZwHJany98raDQkA6o45DEDN1P0N6Cmle1JKO1JKO06ePFnvmwOAmrly/jpz\n5kyjhwOgSc12MXUspdQrSZW/q/6G4JzzvTnn7Tnn7cuXL5/lzQFATc1oDrty/nIfwgDw1jXbxdT3\nJd1d+fpuSd+rzXAAYE4whwGoGbuYSil9R9KTkjanlA6nlD4v6Y8lfTSltE/SRyv/BoCmwxwGoN5s\nz1TO+TeqRB++1hs7f/68Xnnllaq56xJxXSfuPQ2uqyPqiZJ8V9LChQurZlNTU+G2OecwL+kxkqTO\nzs4w7+rqKrp+Nz7X4+S4x6a7uzvM3f533OMTdUW546Z030XHneQ7ulyPi+uZ+r3f+70w/9znPhfm\n9VarOWxyclIDAwNVc9cXNjw8HOZufnPvOR0ZGQlz18U0NjY2621dz1xpj5K7fcedI27+6+npCXM3\n/7iuJje/9PX1Fd3+ypXx5ysuXrxYNVu9enW4rdt3bv5yc7vbd+64d8derd5+RAM6AABAARZTAAAA\nBVhMAQAAFGAxBQAAUIDFFAAAQAEWUwAAAAVYTAEAABSwPVO1NDExod27d1fNW1pawu337NkT5pOT\nk2Hu+i5cF5HrkYm2dz0npT1S7r676z937lyYu/G7rhC37934Wltbw9z1tExMTIS548YfHbvuvrmx\nu33vOn7Onz8f5u7YOXv2bJivW7cuzG8U4+PjevHFF6vmrgfK9X25c9DNT/XsUot6iCR/jLrz13Wx\nuWPcbe9+FZAbf1tbW5i75y63/9yxUdpT6MZf0pPnbtvNL+551eXusT19+nTR9c8Ur0wBAAAUYDEF\nAABQgMUUAABAARZTAAAABVhMAQAAFGAxBQAAUIDFFAAAQIE57ZkaGxvTc889VzXv7OwMtz969GiY\nDw0NhXlp11F7e3uYj4+PV81cT4jrGeno6Ahz1+Ny5syZMHcdN6VdIG58bnv32Lnrd1xPzNjYWJi7\nLpZId3d3Ue76jVzHjTvuR0ZGwvzZZ58N8xtJdJy6Pi93jLiuo9IuIyeag1zPkxtbSUffTLh9765/\ndHQ0zF1Pnbt+N/+Wzs8ud/NX9Nxb2pPntne5O/YWL14c5tHzslQ2d1+JV6YAAAAKsJgCAAAowGIK\nAACgAIspAACAAiymAAAACrCYAgAAKMBiCgAAoMCc9kzlnMO+jgMHDoTbr1+/PsxdD5Try+nr6wvz\n3t7eMD979mzVbO/eveG2bW1tYX7HHXeE+fLly8P86aefDvPDhw+HeWlHl+uBcj0trsvE9azcdNNN\nYf72t789zF2X0759+6pmrmNnzZo1Ye76hxzXz+Y6glxPizu2bxSXLl0Kz3HXdeTOAfc4ux6p0p6p\niDuG3fnvjjG3bxYtWhTmrgfKzV+ua8jNr27+ctu7+9/T0xPmrkeqZH52+971QLmePHdsudt3553r\naHTHxkzxyhQAAEABFlMAAAAFWEwBAAAUYDEFAABQgMUUAABAARZTAAAABVhMAQAAFLA9Uymlb0j6\nhKTjOeetlcu+Ium3JJ2ofNuXc84PueuaP39+2Dnh+h5cz5Pr0nB9FJOTk2EedcxIcdeI60FxXRiu\na8N1ebgeE3ffXA+W62m5cOFCmDujo6Nh7u7f0qVLw7yzszPMXY9MtP9K+4Nch5br8HHHtRtff39/\nmB86dCjMXUdXvdVqDmtpaQm77lwXkNvPbv5zc4jr6XPzYzQHubnTnf9ufnLc2N055HqYnHXr1oW5\nm59cl5x7bN386+YIt/+j3B23Q0NDYV567AwMDIR5aQ/WqlWrwnymZvLK1Dclfewql38157yt8scu\npACgQb4p5jAAdWQXUznnxyXFS08AaFLMYQDqreQ9U19MKe1MKX0jpRT/DAUAmg9zGICamO1i6i8l\nbZS0TdKgpD+t9o0ppXtSSjtSSjvcz3UBYI7MaA67cv4qfd8NgBvXrBZTOedjOeepnPMlSV+T9O7g\ne+/NOW/POW93v4gYAObCTOewK+cv9yERAG9ds1pMpZSu/Fjdr0p6sTbDAYD6Yw4DUEszqUb4jqQP\nSlqeUjos6Q8lfTCltE1SlvSqpN+u4xgBYNaYwwDUm11M5Zx/4yoXf302N5ZzDvuG7rjjjnB71+Pi\n+iI2btwY5q5LyIn6OJYsWRJu67qC+vr6wnzFihVh/t73vjfMu7q6wtzt+5xzmLsOnZRSmLseLNcj\ndeutt4a568Fy13/nnXdWzdx9dz0uroPGjc113LiOLnfejIyMhPnLL78c5vVWqzmss7NTv/iLv1g1\nd8eoO8ddl5I7x/7+7/8+zF0fz2233TbrbV3u5iendH5xXUeup8o9N7guN3f9pePbtWtXmLtjK5r/\n3fl96tSpMHcdXe68GB8fD3PXU+Wu/6abbgrzmaIBHQAAoACLKQAAgAIspgAAAAqwmAIAACjAYgoA\nAKAAiykAAIACLKYAAAAK2J6pWpqamgq7WFxXh/vdfq5vwindPupKcl0XCxbED4XbNy53PSOu58R1\n6JR2fbj777qUli1bFuZu/wwMDIS56wmLuqJcR467767jxu1792ucVq5cGebLly8P89HR0TC/UUxO\nTurw4cNVc/c4ui4kd466x3nt2rVF20fniPtVOq6nzm2/ePHiMHf7xs0vjut6c/vOjc/1cLlz3HU9\n7dy5M8x3794d5tGx4x6bD3zgA2G+YcOGMHf71j03ufltaGgozIeHh8N8pnhlCgAAoACLKQAAgAIs\npgAAAAqwmAIAACjAYgoAAKAAiykAAIACLKYAAAAKzGnPVFtbm972trdVzV2XkOsSKe0acV1Kricm\n4nqQXA9JZ2fnrG9bkrq7u8P8ne98Z5iPj4+HuRt/1MEl+R4o1wPjrt8dGytWrAjzki4o1zN14cKF\nMG9tbQ1zd99dj5R77FzPyy//8i+H+Y9+9KMwv15MTExo//79VXPXp+P2szsG3TnQ19cX5q7L6Pjx\n41WzsbGxcNsDBw6Eues5cl1D7hxx54Cbu9054s5h99i4Y8N1JbmeqUOHDoX5nj17wjya37du3Rpu\n63qmnnjiiTB3/ZG33357mLu5/eLFi2H+13/912E+U7wyBQAAUIDFFAAAQAEWUwAAAAVYTAEAABRg\nMQUAAFCAxRQAAEABFlMAAAAF5rRn6tKlS2GnREdHR7h9aRfI8uXLw9z1sLgulHnzqq9NXc+J6ymp\nN7dvXVeHy51o30l+/7jbn5iYCPO2trYwd6KONDc2d2y449op6UeTpDNnzoS56yC6UbS0tKi/v79q\nfvTo0XD75557LszvvPPOMHddc+44cX1l0TnQ09MTblvak+fmXpe7LjR3DLtzJOrgkqTBwcEwP3ny\nZJi7nizXM+X2j+sgi7j5y92264E6depU0fbuuHfHZuncfxmvTAEAABRgMQUAAFCAxRQAAEABFlMA\nAAAFWEwBAAAUYDEFAABQgMUUAABAAdszlVLql/QtSaslXZJ0b875z1NKyyT9jaT1kl6V9Omc8+no\nus6ePasnnniiau66Pt71rneF+fDwcJi7ro8LFy6EuevTmJycrJq5niR3313e3t4e5lE/jiTt27cv\nzJ1Vq1aFueuZOXv2bJgfPHgwzF0H2ObNm8PcdQCNj4+HedTF4o4b16/mDA0NhbnraVmwIJ4G1q5d\nG+YvvfRSmDdSLeev1tZWrVu3rmruuoheffXVMF+8eHGYuy4416VUMj+6jip3DLmeKtcB6OZudw4t\nW7YszN2+d/NXb29vmK9evTrMHddhtmfPnjB3+y/qf3Q9TW7fb9u2LczXr18f5m7+cs+N7rnBPXYz\nNZNXpi5K+v2c8xZJ75H0hZTS2yR9SdIjOedNkh6p/BsAmgnzF4C6s4upnPNgzvm5ytejkvZI6pP0\nSUn3Vb7tPkmfqtcgAWA2mL8AzIVres9USmm9pHdIekrSqpzzoDQ9YUmKX4MGgAZi/gJQLzNeTKWU\nOiX9naTfzTnHvyjo57e7J6W0I6W0w70nCQDqoRbzl3vPEYC3rhktplJKCzU9EX075/xA5eJjKaXe\nSt4r6arvvsw535tz3p5z3u7eSAYAtVar+au7u3tuBgzgumMXU2n611l/XdKenPOfXRF9X9Ldla/v\nlvS92g8PAGaP+QvAXLDVCJLeJ+lzknallJ6vXPZlSX8s6f6U0uclvS7p39RniAAwa8xfAOrOLqZy\nzv8sKVWJP3xNN7ZgQdj3MW9e/EKZ69LYu3dvmB84cCDMXRfJiRMnwvzYsWNVM9fVE3VUSdLSpUuL\n8omJiTB/6KGHwtz1LG3cuDHMXY+Lez9KaZfRZz/72TB/9NFHw9x1+ETHhtt3K1asCHPX4xIdd5I0\nOjoa5lFHliR9/OMfD/PSDp16quX8NTExof3791fNo0zy+9l1ObmutOkX4aobGxsL86jrzc1P58+f\nD3PHvZ/29OmwAsz2MLl977qU/vEf/zHM3XOXm39cD5ebP3POYe5EXU1dXV3htm7+cv1o7rh0XM+U\ne2zcc/NM0YAOAABQgMUUAABAARZTAAAABVhMAQAAFGAxBQAAUIDFFAAAQAEWUwAAAAVmUtpZMykl\nLVy4sGru+h6iHhTJd5X09fWFuft1N67LJOpa6uzsDLd1981xXUILFsQPdXt7e5i7rqQnn3wyzF3P\nlRuf6wBzPSuuy8T1SLljK+qCmpqaCrd1+3b+/Plh3tbWFubuvrueFtcx5Dp6bhQTExNh153r+3I9\nUs8++2yYu/mxv78/zF1fUDQHRPO25Lt8XA+Vmx9WrVpVdP3u/H7wwQeLcncOrlmzJszdc9Px41f9\nbUf/35EjR8LcdSRGj717bNy+dR1fQ0NDYe7mHzf3u/nXnbczxStTAAAABVhMAQAAFGAxBQAAUIDF\nFAAAQAEWUwAAAAVYTAEAABRgMQUAAFBgTnumpqamNDIyUjV3fTuup8X1Vaxfvz7MXVfKkiVLwjzq\ncXFdFq7jqlRPT0+Ynzx5Msxd14jrYXJdH+7+u64S19O1cuXKMHfHVkkPmOuJcvvG3Xa9jx3XU+U6\nym4Uk5OTYZ/Pvn37wu1dH9cDDzwQ5ocOHQrzj3zkI2G+efPmMF+8eHHVzJ3fruvH3Xd3DLueK3f+\nunNs165dYV56Dh44cCDMP/rRj4a569l79NFHw9zN393d3VWz0h666Dlf8v2N7nnXdTi6Hix3+zPF\nK1MAAAAFWEwBAAAUYDEFAABQgMUUAABAARZTAAAABVhMAQAAFJjTaoTW1lbdeuutVfPly5eH27uP\nMLqPj7qPr7qPz7qPl7a1tVXNFiyId7X7+Kb7eOj58+fD3BkdHQ1z99FoVyvhuI9WO258UW2F5D96\n7e5flLvHPqUU5u6xddUE7vodV0vxVqlGmD9/fngebtiwIdz+xIkTYe7mN1ed8Mgjj4T5li1bwnzr\n1q1VM1cNcO7cuTDfuHFjUd7f3x/mq1atCnNXm3P69Okwd/ODy93+c+fQHXfcEebuudPdv46OjqqZ\nq9VxtTPuefPUqVNhvm7dujB3j727/lrNX7wyBQAAUIDFFAAAQAEWUwAAAAVYTAEAABRgMQUAAFCA\nxRQAAEABFlMAAAAFbM9USqlf0rckrZZ0SdK9Oec/Tyl9RdJvSbpcnvLlnPND0XVNTk5qYGCgan7b\nbbeFY3F9Ea6Pp7OzM8xdF8miRYvCPOpxGR8fD7d9/vnnw9z1uLiuDddx43qUXA+U61KanJwMc9eF\n5K7f9by4Y6OkR0oq68ly9721tTXML126VHT9TmlPViPVcv5asGCBVqxYUTWPunokac2aNWHe19cX\n5idPngxz11O1c+fOMH/22WerZq6Dz3E9ea6r6JZbbglz16HlHhu37w8dOhTm7hwZGxsL82PHjoW5\n65F673vfG+a/8Au/EOaDg4NVs7Vr14bbug4t97ztjut9+/aF+csvvxzmzzzzTJgfPHgwzGdqJqWd\nFyX9fs75uZRSl6RnU0oPV7KolTI7AAANTklEQVSv5pz/W01GAgC1x/wFoO7sYirnPChpsPL1aEpp\nj6R4GQ8ATYD5C8BcuKb3TKWU1kt6h6SnKhd9MaW0M6X0jZTS0hqPDQBqhvkLQL3MeDGVUuqU9HeS\nfjfnPCLpLyVtlLRN0//z+9Mq292TUtqRUtrhfkcPANRDLeYv975FAG9dM1pMpZQWanoi+nbO+QFJ\nyjkfyzlP5ZwvSfqapHdfbduc87055+055+3uDdwAUGu1mr/eKr/QGcC1s4upNP1Rna9L2pNz/rMr\nLu+94tt+VdKLtR8eAMwe8xeAuTCTT/O9T9LnJO1KKV3+/P6XJf1GSmmbpCzpVUm/XZcRAsDsMX8B\nqLuZfJrvnyVdrUgm7GS5mqmpKQ0PD1fNX3/99XB712fh+ni6urqKrv/mm28O86gLxHUBRf1bkvTa\na6+Fues5efHFsv94ux4n93640i4i1+PkemzcsVV6+9H9c/1m7rpdx5Xr8Fq2bFmYu/6jixcvhvlj\njz0W5o1Uy/mrpaVFN910U9XcnaPuHHDHiZt/RkZGwtz16B05cmRWmeS7gs6cORPmriPrZz/7WZjv\n2LEjzF1PlXsLSktLS5g77rGJep4kadOmTWG+bdu2ML/99tvDfM+ePVWzCxcuhNt+7WtfC3PXoeXm\n5h//+Mdh7joE3XHv5seZogEdAACgAIspAACAAiymAAAACrCYAgAAKMBiCgAAoACLKQAAgAIspgAA\nAArMpLSzZubPn6/u7u6quevycH08rivkn/7pn8LccV1Khw4dqpq5sbuOK9cj5bqIon4cKe4ZkXxX\nhxtfKdclEh1XkrR0afx7bFeuXBnmx48fD/Oo58r1C7nj3nWURf1mktTT0xPm+/btC3PXkeP6lW4U\nbW1t2rp1a9XcnQPR/CBJ4+PjYe569ObPnx/m7hyI+sY2btwYbnvixIkwf+WVV8LcdRGNjY0VXf/p\n06fD3PXoufnP9dy55w53Dj3xxBNh3tvbG+ZujlmxYkXVzHWM7dq1K8yjbsmZ5O68cHN3dN8k/9wx\nU7wyBQAAUIDFFAAAQAEWUwAAAAVYTAEAABRgMQUAAFCAxRQAAEABFlMAAAAF5rRnat68eWpvb6+a\nnzp1Ktz+6NGjYT4wMBDmU1NTYe56Ylzfj+u5ikT7RfJj7+vrC3PXReTuu+spcffd9WC5nhdn2bJl\nYe66ljZt2hTmzzzzTJifO3euauY6vlzPieupuu2228LcHTsHDhwIc7dvXP/R/fffH+bXiwULFoSd\nNe4cWL16dZi7LiTXteb6eNz8GvVUufnJ3bcNGzaEuesacl1HrqfJ9VhNTk6GuTuH3GPvegSffPLJ\nMHc9Wp/4xCfC3PVknTlzZlaZ5DsU3bEzODgY5hcuXAjzrq6uMHc9VO65aaZ4ZQoAAKAAiykAAIAC\nLKYAAAAKsJgCAAAowGIKAACgAIspAACAAiymAAAACsxpz9SCBQvCvh/X9+B6niYmJsL84sWLYd7W\n1hbmrg8o6krq6OgIt3U9K65D5vXXXw/z48ePh7nbd66HasmSJWG+ePHiMHc9UW7/RR05ku8g++lP\nfxrmIyMjYR710EQdVJK0du3aML/lllvC3HH9bP39/WH+/ve/P8zXrVsX5jdKz1RKKTzO3DHq+sbW\nrFkT5q4Lyc1ve/fuDfNDhw5Vzdz84M4/Nz+4fee6gjZu3Bjm0X2T/P1z88fo6GiYu44vN77NmzeH\nuXvufPXVV8M8em5zPU87duwIc3ff3XOb43r4XIeh6yCcKV6ZAgAAKMBiCgAAoACLKQAAgAIspgAA\nAAqwmAIAACjAYgoAAKAAiykAAIACtmcqpbRI0uOSWivf/7c55z9MKW2Q9F1JyyQ9J+lzOeewkOLS\npUsaGxurmru+B9eH47qaXN9OzjnMXc9V1EXkeko6Oztnfd2StHz58jB3PSTOokWLwry9vb1oe9e1\n5LqM3P13PVuuo8f1bLW2tlbN3GO7atWqMF+9enWYr1+/PsxXrFgR5tHYJd/T4vZto9VyDov6lNwx\n4s4BN/+43Im60KT4ODh27Fi4resKcvOX6wpy85frqdq0aVOYu2PcnUOua+n06dNh7h6bnTt3hvlL\nL70U5m5+jeYQNz+489/1ozmuwyxaU0jS0NBQmLe0tFzzmK5mJs+w5yXdmXN+u6Rtkj6WUnqPpD+R\n9NWc8yZJpyV9viYjAoDaYg4DUFd2MZWnna38c2HlT5Z0p6S/rVx+n6RP1WWEAFCAOQxAvc3oZz8p\npfkppeclHZf0sKQDkoZzzpd/NnJYUl99hggAZZjDANTTjBZTOeepnPM2SWslvVvSlqt929W2TSnd\nk1LakVLa4X5HGQDUw2znsCvnL/feCwBvXdf0ruSc87CkxyS9R1J3SunyOy7XSrrqO6xzzvfmnLfn\nnLe7NykDQD1d6xx25fzlfhk3gLcuu5hKKa1IKXVXvm6T9BFJeyQ9KunXKt92t6Tv1WuQADBbzGEA\n6s1WI0jqlXRfSmm+phdf9+ec/09K6SVJ300p/ZGkn0r6eh3HCQCzxRwGoK7sYirnvFPSO65y+UFN\nv/dgxhYtWqQtW672VoVpp06dCrd3fRdbt269luG8ydmzZ8Pc/ZgyGr8b+4YNG8J88eLFRfnhw4fD\n/B3veNND/HNuv/32MHf7xnUtuR6prq6uMHc9Na7n5V3veleY33bbbWEe9eC4DhvXn+Y6Ylz/meN6\nYEZHR8O82X98X6s5bHJyMjyP3DHqdHd3F23v9PXF76+PupRcR99rr70W5gcOHAjzCxfCeq/iY9x1\ngLmuoZtvvjnM3fhcB6Lr6Tp06FCYu/cjDw4Ozjp3c7frP3MdYK5/zXUI9vb2Fl1/rdCADgAAUIDF\nFAAAQAEWUwAAAAVYTAEAABRgMQUAAFCAxRQAAEABFlMAAAAFkuuIqOmNpXRC0pWFJMslnZyzAVy7\nZh5fM49Nau7xNfPYpBtvfOtyztVLjK4TzF8118zja+axSc09vmYem1Sn+WtOF1NvuvGUduSctzds\nAEYzj6+ZxyY19/iaeWwS47teNPt+YHyz18xjk5p7fM08Nql+4+PHfAAAAAVYTAEAABRo9GLq3gbf\nvtPM42vmsUnNPb5mHpvE+K4Xzb4fGN/sNfPYpOYeXzOPTarT+Br6nikAAIDrXaNfmQIAALiuNWQx\nlVL6WErp5ZTS/pTSlxoxhkhK6dWU0q6U0vMppR1NMJ5vpJSOp5RevOKyZSmlh1NK+yp/L22y8X0l\npXSksg+fTyl9vEFj608pPZpS2pNS2p1S+veVyxu+/4KxNcu+W5RSejql9EJlfP+5cvmGlNJTlX33\nNymllkaMr5GYw65pLMxfsx9b085fZnzNsv/mbg7LOc/pH0nzJR2QdLOkFkkvSHrbXI/DjPFVScsb\nPY4rxvMBSe+U9OIVl/1XSV+qfP0lSX/SZOP7iqT/0AT7rlfSOytfd0n6maS3NcP+C8bWLPsuSeqs\nfL1Q0lOS3iPpfkm/Xrn8f0j6nUaPdY73C3PYtY2F+Wv2Y2va+cuMr1n235zNYY14ZerdkvbnnA/m\nnC9I+q6kTzZgHNeNnPPjkobecPEnJd1X+fo+SZ+a00Fdocr4mkLOeTDn/Fzl61FJeyT1qQn2XzC2\nppCnna38c2HlT5Z0p6S/rVze0GOvQZjDrgHz1+w18/xlxtcU5nIOa8Riqk/SoSv+fVhNtPMrsqQf\npZSeTSnd0+jBVLEq5zwoTR/QklY2eDxX88WU0s7Ky+gNexn/spTSeknv0PT/Tppq/71hbFKT7LuU\n0vyU0vOSjkt6WNOvyAznnC9WvqUZz996Yw4r11TnXxVNcQ5e1szzl8Qc1ojFVLrKZc32kcL35Zzf\nKelfS/pCSukDjR7QdegvJW2UtE3SoKQ/beRgUkqdkv5O0u/mnEcaOZY3usrYmmbf5Zyncs7bJK3V\n9CsyW672bXM7qoZjDrvxNc05KDX3/CUxh0mNWUwdltR/xb/XShpowDiqyjkPVP4+LulBTT8AzeZY\nSqlXkip/H2/weH5OzvlY5SC+JOlrauA+TCkt1PSJ/u2c8wOVi5ti/11tbM207y7LOQ9LekzT7zfo\nTiktqERNd/7OAeawck1x/lXTTOdgM89f1cbXTPvvsnrPYY1YTD0jaVPl3fQtkn5d0vcbMI6rSil1\npJS6Ln8t6S5JL8ZbNcT3Jd1d+fpuSd9r4Fje5PKJXvGratA+TCklSV+XtCfn/GdXRA3ff9XG1kT7\nbkVKqbvydZukj2j6PRGPSvq1yrc13bE3B5jDyjX8/Is00TnYtPOXxBz2cxr0DvuPa/pd/wck/cdG\njCEY282a/nTOC5J2N8P4JH1H0y+VTmr6f8Wfl9Qj6RFJ+yp/L2uy8f2VpF2Sdmr6xO9t0Njer+mX\ncHdKer7y5+PNsP+CsTXLvrtd0k8r43hR0n+qXH6zpKcl7Zf0vyW1NurYa9Qf5rBrGg/z1+zH1rTz\nlxlfs+y/OZvDaEAHAAAoQAM6AABAARZTAAAABVhMAQAAFGAxBQAAUIDFFAAAQAEWUwAAAAVYTAEA\nABRgMQUAAFDg/wHV3MopDN7uxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4fc9b66320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "ax[0].imshow(X_train100[0][0,...], cmap='gray')\n",
    "ax[0].set_title(y_train100[0])\n",
    "ax[1].imshow(X_train100[100][0,...], cmap='gray')\n",
    "ax[1].set_title(y_train100[100]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Redifine model with shared weights from previous task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "\n",
    "net.add_module('Conv1', nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, padding=1)) #Conv1\n",
    "net.Conv1.weight, net.Conv1.bias = weights['Conv1'], biases['Conv1']\n",
    "\n",
    "net.add_module('Conv1-2', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1)) #Conv1-2\n",
    "net.__dict__['_modules']['Conv1-2'].weight = weights['Conv1-2']\n",
    "net.__dict__['_modules']['Conv1-2'].bias = biases['Conv1-2']\n",
    "\n",
    "net.add_module('bn1', nn.BatchNorm2d(256)) #bn1\n",
    "net.bn1.weight, net.bn1.bias = weights['bn1'], biases['bn1']\n",
    "\n",
    "net.add_module('relu1', nn.LeakyReLU()) #ReLU1\n",
    "net.add_module('mp1', nn.MaxPool2d(kernel_size=2)) #MP1\n",
    "\n",
    "net.add_module('Conv2', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1)) #Conv2\n",
    "net.Conv2.weight, net.Conv2.bias = weights['Conv2'], biases['Conv2']\n",
    "\n",
    "net.add_module('bn2', nn.BatchNorm2d(512)) #BN2\n",
    "net.bn2.weight, net.bn2.bias = weights['bn2'], biases['bn2'] \n",
    "\n",
    "net.add_module('relu2', nn.LeakyReLU()) #ReLU2\n",
    "net.add_module('mp2', nn.MaxPool2d(kernel_size=2)) #MP2\n",
    "\n",
    "net.add_module('Conv3', nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1)) #Conv3\n",
    "net.Conv3.weight, net.Conv3.bias = weights['Conv3'], biases['Conv3'] \n",
    "\n",
    "net.add_module('bn3', nn.BatchNorm2d(1024)) #BN3\n",
    "net.bn3.weight, net.bn3.bias = weights['bn3'], biases['bn3'] \n",
    "\n",
    "net.add_module('relu3', nn.LeakyReLU())\n",
    "\n",
    "net.add_module('av1', nn.AvgPool2d(kernel_size=8)) #AV1\n",
    "net.add_module('flatten', Flatten()) #Flatten\n",
    "net.add_module('fc1', nn.LeakyReLU()) #fc1\n",
    "\n",
    "net.add_module('Lin', nn.Linear(1024, 2)) #Linear\n",
    "net.add_module('SM', nn.Softmax(dim=1)) #SM\n",
    "\n",
    "net.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rotation done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34cef49b6fd343e09adbbe44e79060b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's again augment a bit\n",
    "X_train2_aug, y_train2_aug = augment_dataset(X_train100, y_train100, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam([{'params': net.Conv1.parameters(), 'lr':1e-6},\n",
    "                        {'params': net.__dict__['_modules']['Conv1-2'].parameters(), 'lr':1e-6},\n",
    "                        {'params': net.bn1.parameters(), 'lr':1e-6},\n",
    "                        {'params': net.relu1.parameters()},\n",
    "                        {'params': net.mp1.parameters()},\n",
    "                        {'params': net.Conv2.parameters(), 'lr':1e-6},\n",
    "                        {'params': net.bn2.parameters(), 'lr':1e-6},\n",
    "                        {'params': net.relu2.parameters()},\n",
    "                        {'params': net.mp2.parameters()},\n",
    "                        {'params': net.Conv3.parameters(), 'lr':1e-6},\n",
    "                        {'params': net.bn3.parameters(), 'lr':1e-6},\n",
    "                        {'params': net.relu3.parameters()},\n",
    "                        {'params': net.av1.parameters()},\n",
    "                        {'params': net.flatten.parameters()},\n",
    "                        {'params': net.fc1.parameters()},\n",
    "                        {'params': net.Lin.parameters()},\n",
    "                        {'params': net.SM.parameters()}],\n",
    "                        lr=1e-2)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_loss(X_batch, y_batch):\n",
    "    X_batch = Variable(torch.FloatTensor(X_batch).cuda())\n",
    "    y_batch = Variable(torch.LongTensor(y_batch).cuda())\n",
    "    logits = net(X_batch)\n",
    "    return F.cross_entropy(logits, y_batch).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a1f51d77d348ed81b628a45c9b8cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/use/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/use/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/use/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 15 took 5.938s\n",
      "  training loss (in-iteration): \t0.406519\n",
      "  validation accuracy: \t\t\t95.51 %\n",
      "Epoch 2 of 15 took 5.823s\n",
      "  training loss (in-iteration): \t0.403737\n",
      "  validation accuracy: \t\t\t95.53 %\n",
      "Epoch 3 of 15 took 5.548s\n",
      "  training loss (in-iteration): \t0.401626\n",
      "  validation accuracy: \t\t\t95.48 %\n",
      "Epoch 4 of 15 took 5.696s\n",
      "  training loss (in-iteration): \t0.399845\n",
      "  validation accuracy: \t\t\t95.10 %\n",
      "Epoch 5 of 15 took 5.529s\n",
      "  training loss (in-iteration): \t0.397727\n",
      "  validation accuracy: \t\t\t95.12 %\n",
      "Epoch 6 of 15 took 5.551s\n",
      "  training loss (in-iteration): \t0.395864\n",
      "  validation accuracy: \t\t\t94.90 %\n",
      "Epoch 7 of 15 took 5.592s\n",
      "  training loss (in-iteration): \t0.393932\n",
      "  validation accuracy: \t\t\t94.87 %\n",
      "Epoch 8 of 15 took 5.603s\n",
      "  training loss (in-iteration): \t0.392854\n",
      "  validation accuracy: \t\t\t94.92 %\n",
      "Epoch 9 of 15 took 5.636s\n",
      "  training loss (in-iteration): \t0.391769\n",
      "  validation accuracy: \t\t\t95.01 %\n",
      "Epoch 10 of 15 took 5.661s\n",
      "  training loss (in-iteration): \t0.388929\n",
      "  validation accuracy: \t\t\t95.05 %\n",
      "Epoch 11 of 15 took 5.575s\n",
      "  training loss (in-iteration): \t0.382860\n",
      "  validation accuracy: \t\t\t94.63 %\n",
      "Epoch 12 of 15 took 5.757s\n",
      "  training loss (in-iteration): \t0.379408\n",
      "  validation accuracy: \t\t\t94.62 %\n",
      "Epoch 13 of 15 took 5.550s\n",
      "  training loss (in-iteration): \t0.376365\n",
      "  validation accuracy: \t\t\t94.62 %\n",
      "Epoch 14 of 15 took 5.704s\n",
      "  training loss (in-iteration): \t0.373809\n",
      "  validation accuracy: \t\t\t94.67 %\n",
      "Epoch 15 of 15 took 5.547s\n",
      "  training loss (in-iteration): \t0.371930\n",
      "  validation accuracy: \t\t\t94.74 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    start_time = time.time()\n",
    "    net.train(True) # enable dropout / batch_norm training behavior\n",
    "    for X_batch, y_batch in iterate_minibatches(X_train2_aug, y_train2_aug, batch_size):\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "        \n",
    "    if (epoch+1)%5==0 and (epoch+1)<=10:\n",
    "        opt.param_groups[0]['lr'] = opt.param_groups[0]['lr']/2\n",
    "    elif (epoch+1)>10 and (epoch+1)%2 == 0:\n",
    "        opt.param_groups[0]['lr'] = opt.param_groups[0]['lr']/10\n",
    "    \n",
    "    # And a full pass over the validation data:\n",
    "    net.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in iterate_minibatches(X_val100, y_val100, batch_size):\n",
    "        logits = net(Variable(torch.FloatTensor(X_batch).cuda()))\n",
    "        y_pred = logits.max(1)[1].cpu().data.numpy()\n",
    "        val_accuracy.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t90.00 %\n",
      "Achievement unlocked: 110lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "net.train(False) # disable dropout / use averages for batch_norm\n",
    "test_batch_acc = []\n",
    "for X_batch, y_batch in iterate_minibatches(X_test100, y_test100, 100):\n",
    "    logits = net(Variable(torch.FloatTensor(X_batch).cuda()))\n",
    "    y_pred = logits.cpu().max(1)[1].data.numpy()\n",
    "    test_batch_acc.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "test_accuracy = np.mean(test_batch_acc)\n",
    "    \n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 95:\n",
    "    print(\"Double-check, than consider applying for NIPS'18. SRSly.\")\n",
    "elif test_accuracy * 100 > 90:\n",
    "    print(\"U'r freakin' amazin'!\")\n",
    "elif test_accuracy * 100 > 80:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 70:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 60:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 50:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ##### Let's now use the same model with random initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (Conv1): Conv2d (3, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (Conv1-2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu1): LeakyReLU(0.01)\n",
       "  (mp1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (Conv2): Conv2d (256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu2): LeakyReLU(0.01)\n",
       "  (mp2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (Conv3): Conv2d (512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (relu3): LeakyReLU(0.01)\n",
       "  (av1): AvgPool2d(kernel_size=8, stride=8, padding=0, ceil_mode=False, count_include_pad=True)\n",
       "  (flatten): Flatten(\n",
       "  )\n",
       "  (fc1): LeakyReLU(0.01)\n",
       "  (Lin): Linear(in_features=1024, out_features=2)\n",
       "  (SM): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "net.add_module('Conv1', nn.Conv2d(in_channels=3, out_channels=256, kernel_size=3, padding=1))\n",
    "net.add_module('Conv1-2', nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1))\n",
    "net.add_module('bn1', nn.BatchNorm2d(256))\n",
    "net.add_module('relu1', nn.LeakyReLU())\n",
    "net.add_module('mp1', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "net.add_module('Conv2', nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1))\n",
    "net.add_module('bn2', nn.BatchNorm2d(512))\n",
    "net.add_module('relu2', nn.LeakyReLU())\n",
    "net.add_module('mp2', nn.MaxPool2d(kernel_size=2))\n",
    "\n",
    "net.add_module('Conv3', nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1))\n",
    "net.add_module('bn3', nn.BatchNorm2d(1024))\n",
    "net.add_module('relu3', nn.LeakyReLU())\n",
    "\n",
    "net.add_module('av1', nn.AvgPool2d(kernel_size=8))\n",
    "net.add_module('flatten', Flatten())\n",
    "net.add_module('fc1', nn.LeakyReLU())\n",
    "\n",
    "net.add_module('Lin', nn.Linear(1024, 2))\n",
    "net.add_module('SM', nn.Softmax(dim=1))\n",
    "\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.Adam(net.parameters(), lr=1e-2)\n",
    "\n",
    "train_loss = []\n",
    "val_accuracy = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9308accfada4a2d9bfd76f7522d7768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 50 took 5.590s\n",
      "  training loss (in-iteration): \t0.707205\n",
      "  validation accuracy: \t\t\t50.91 %\n",
      "Epoch 2 of 50 took 5.371s\n",
      "  training loss (in-iteration): \t0.644073\n",
      "  validation accuracy: \t\t\t60.18 %\n",
      "Epoch 3 of 50 took 5.635s\n",
      "  training loss (in-iteration): \t0.617619\n",
      "  validation accuracy: \t\t\t62.82 %\n",
      "Epoch 4 of 50 took 5.385s\n",
      "  training loss (in-iteration): \t0.596741\n",
      "  validation accuracy: \t\t\t67.51 %\n",
      "Epoch 5 of 50 took 5.388s\n",
      "  training loss (in-iteration): \t0.578547\n",
      "  validation accuracy: \t\t\t67.49 %\n",
      "Epoch 6 of 50 took 5.599s\n",
      "  training loss (in-iteration): \t0.562597\n",
      "  validation accuracy: \t\t\t69.79 %\n",
      "Epoch 7 of 50 took 5.479s\n",
      "  training loss (in-iteration): \t0.547628\n",
      "  validation accuracy: \t\t\t70.85 %\n",
      "Epoch 8 of 50 took 5.538s\n",
      "  training loss (in-iteration): \t0.535693\n",
      "  validation accuracy: \t\t\t72.09 %\n",
      "Epoch 9 of 50 took 5.400s\n",
      "  training loss (in-iteration): \t0.525641\n",
      "  validation accuracy: \t\t\t73.05 %\n",
      "Epoch 10 of 50 took 5.406s\n",
      "  training loss (in-iteration): \t0.517306\n",
      "  validation accuracy: \t\t\t73.29 %\n",
      "Epoch 11 of 50 took 5.408s\n",
      "  training loss (in-iteration): \t0.509685\n",
      "  validation accuracy: \t\t\t74.21 %\n",
      "Epoch 12 of 50 took 5.526s\n",
      "  training loss (in-iteration): \t0.502864\n",
      "  validation accuracy: \t\t\t75.32 %\n",
      "Epoch 13 of 50 took 5.414s\n",
      "  training loss (in-iteration): \t0.497818\n",
      "  validation accuracy: \t\t\t75.57 %\n",
      "Epoch 14 of 50 took 5.476s\n",
      "  training loss (in-iteration): \t0.492704\n",
      "  validation accuracy: \t\t\t76.04 %\n",
      "Epoch 15 of 50 took 5.561s\n",
      "  training loss (in-iteration): \t0.487283\n",
      "  validation accuracy: \t\t\t76.06 %\n",
      "Epoch 16 of 50 took 5.405s\n",
      "  training loss (in-iteration): \t0.482171\n",
      "  validation accuracy: \t\t\t76.78 %\n",
      "Epoch 17 of 50 took 5.442s\n",
      "  training loss (in-iteration): \t0.477476\n",
      "  validation accuracy: \t\t\t77.46 %\n",
      "Epoch 18 of 50 took 5.457s\n",
      "  training loss (in-iteration): \t0.473296\n",
      "  validation accuracy: \t\t\t77.98 %\n",
      "Epoch 19 of 50 took 5.446s\n",
      "  training loss (in-iteration): \t0.469093\n",
      "  validation accuracy: \t\t\t78.48 %\n",
      "Epoch 20 of 50 took 5.509s\n",
      "  training loss (in-iteration): \t0.458276\n",
      "  validation accuracy: \t\t\t78.78 %\n",
      "Epoch 21 of 50 took 5.412s\n",
      "  training loss (in-iteration): \t0.446261\n",
      "  validation accuracy: \t\t\t79.26 %\n",
      "Epoch 22 of 50 took 5.425s\n",
      "  training loss (in-iteration): \t0.436045\n",
      "  validation accuracy: \t\t\t79.79 %\n",
      "Epoch 23 of 50 took 5.469s\n",
      "  training loss (in-iteration): \t0.427275\n",
      "  validation accuracy: \t\t\t80.03 %\n",
      "Epoch 24 of 50 took 5.418s\n",
      "  training loss (in-iteration): \t0.420179\n",
      "  validation accuracy: \t\t\t80.43 %\n",
      "Epoch 25 of 50 took 5.431s\n",
      "  training loss (in-iteration): \t0.414091\n",
      "  validation accuracy: \t\t\t80.83 %\n",
      "Epoch 26 of 50 took 5.421s\n",
      "  training loss (in-iteration): \t0.409215\n",
      "  validation accuracy: \t\t\t81.07 %\n",
      "Epoch 27 of 50 took 5.442s\n",
      "  training loss (in-iteration): \t0.405036\n",
      "  validation accuracy: \t\t\t81.38 %\n",
      "Epoch 28 of 50 took 5.433s\n",
      "  training loss (in-iteration): \t0.400981\n",
      "  validation accuracy: \t\t\t81.65 %\n",
      "Epoch 29 of 50 took 5.440s\n",
      "  training loss (in-iteration): \t0.397428\n",
      "  validation accuracy: \t\t\t81.94 %\n",
      "Epoch 30 of 50 took 5.493s\n",
      "  training loss (in-iteration): \t0.393730\n",
      "  validation accuracy: \t\t\t82.18 %\n",
      "Epoch 31 of 50 took 5.651s\n",
      "  training loss (in-iteration): \t0.390585\n",
      "  validation accuracy: \t\t\t82.37 %\n",
      "Epoch 32 of 50 took 5.470s\n",
      "  training loss (in-iteration): \t0.387733\n",
      "  validation accuracy: \t\t\t82.61 %\n",
      "Epoch 33 of 50 took 5.498s\n",
      "  training loss (in-iteration): \t0.384226\n",
      "  validation accuracy: \t\t\t82.86 %\n",
      "Epoch 34 of 50 took 5.524s\n",
      "  training loss (in-iteration): \t0.381770\n",
      "  validation accuracy: \t\t\t83.05 %\n",
      "Epoch 35 of 50 took 5.435s\n",
      "  training loss (in-iteration): \t0.379869\n",
      "  validation accuracy: \t\t\t83.21 %\n",
      "Epoch 36 of 50 took 5.444s\n",
      "  training loss (in-iteration): \t0.377872\n",
      "  validation accuracy: \t\t\t83.40 %\n",
      "Epoch 37 of 50 took 5.438s\n",
      "  training loss (in-iteration): \t0.376299\n",
      "  validation accuracy: \t\t\t83.56 %\n",
      "Epoch 38 of 50 took 5.443s\n",
      "  training loss (in-iteration): \t0.374717\n",
      "  validation accuracy: \t\t\t83.73 %\n",
      "Epoch 39 of 50 took 5.447s\n",
      "  training loss (in-iteration): \t0.373263\n",
      "  validation accuracy: \t\t\t83.86 %\n",
      "Epoch 40 of 50 took 5.445s\n",
      "  training loss (in-iteration): \t0.372244\n",
      "  validation accuracy: \t\t\t84.48 %\n",
      "Epoch 41 of 50 took 5.454s\n",
      "  training loss (in-iteration): \t0.371658\n",
      "  validation accuracy: \t\t\t85.11 %\n",
      "Epoch 42 of 50 took 5.428s\n",
      "  training loss (in-iteration): \t0.370875\n",
      "  validation accuracy: \t\t\t85.70 %\n",
      "Epoch 43 of 50 took 5.450s\n",
      "  training loss (in-iteration): \t0.370328\n",
      "  validation accuracy: \t\t\t86.14 %\n",
      "Epoch 44 of 50 took 5.443s\n",
      "  training loss (in-iteration): \t0.369588\n",
      "  validation accuracy: \t\t\t86.51 %\n",
      "Epoch 45 of 50 took 5.445s\n",
      "  training loss (in-iteration): \t0.369236\n",
      "  validation accuracy: \t\t\t86.90 %\n",
      "Epoch 46 of 50 took 5.443s\n",
      "  training loss (in-iteration): \t0.368862\n",
      "  validation accuracy: \t\t\t87.17 %\n",
      "Epoch 47 of 50 took 5.442s\n",
      "  training loss (in-iteration): \t0.368530\n",
      "  validation accuracy: \t\t\t87.41 %\n",
      "Epoch 48 of 50 took 5.455s\n",
      "  training loss (in-iteration): \t0.368367\n",
      "  validation accuracy: \t\t\t87.64 %\n",
      "Epoch 49 of 50 took 5.458s\n",
      "  training loss (in-iteration): \t0.368267\n",
      "  validation accuracy: \t\t\t87.86 %\n",
      "Epoch 50 of 50 took 5.444s\n",
      "  training loss (in-iteration): \t0.367853\n",
      "  validation accuracy: \t\t\t88.24 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "batch_size = 128\n",
    "\n",
    "for epoch in tqdm_notebook(range(num_epochs)):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    start_time = time.time()\n",
    "    net.train(True) # enable dropout / batch_norm training behavior\n",
    "    for X_batch, y_batch in iterate_minibatches(X_train2_aug, y_train2_aug, batch_size):\n",
    "        # train on batch\n",
    "        loss = compute_loss(X_batch, y_batch)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_loss.append(loss.cpu().data.numpy()[0])\n",
    "        \n",
    "    if (epoch+1)%5==0:\n",
    "        opt.param_groups[0]['lr'] = opt.param_groups[0]['lr']/2\n",
    "    \n",
    "    # And a full pass over the validation data:\n",
    "    net.train(False) # disable dropout / use averages for batch_norm\n",
    "    for X_batch, y_batch in iterate_minibatches(X_val100, y_val100, batch_size):\n",
    "        logits = net(Variable(torch.FloatTensor(X_batch).cuda()))\n",
    "        y_pred = logits.max(1)[1].cpu().data.numpy()\n",
    "        val_accuracy.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "        np.mean(train_loss[-len(X_train) // batch_size :])))\n",
    "    print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "        np.mean(val_accuracy[-len(X_val) // batch_size :]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t80.50 %\n",
      "Achievement unlocked: 110lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "net.train(False) # disable dropout / use averages for batch_norm\n",
    "test_batch_acc = []\n",
    "for X_batch, y_batch in iterate_minibatches(X_test100, y_test100, 100):\n",
    "    logits = net(Variable(torch.FloatTensor(X_batch).cuda()))\n",
    "    y_pred = logits.cpu().max(1)[1].data.numpy()\n",
    "    test_batch_acc.append(np.mean(y_batch == y_pred))\n",
    "\n",
    "test_accuracy = np.mean(test_batch_acc)\n",
    "    \n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 95:\n",
    "    print(\"Double-check, than consider applying for NIPS'18. SRSly.\")\n",
    "elif test_accuracy * 100 > 90:\n",
    "    print(\"U'r freakin' amazin'!\")\n",
    "elif test_accuracy * 100 > 80:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 70:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 60:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 50:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ##### Compare fine-tuned model and the one with a random initialization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed that the model with random initialization can still achieve good accuracy (but probably because of just such dataset). However, it requires much more time to train in terms of numbers of epoches to converge to more or less good performance. While fine-tuning I didn't prevent the layers with learned weights from learning, but I specified a small learning rate for them. I found it's a good idea, because it slightly enhaced a performance and because of the tiny dataset, it's not so expensive. All in all, fine-tuned model needs much less time to train and accuracy is better for almost 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `Artem Moskalev`, and here's my story\n",
    "\n",
    "A long time ago in a galaxy far far away, when it was still more than an hour before the deadline, I got an idea:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* the idea\n",
    "\n",
    "The main idea was to adopt some principles of AlexNet/VGG/InceptionNet in more simple and shallow network. My choice of architecture is not so sophisticated I guess, but it works well and I did some tricks to make it better.\n",
    "\n",
    "* brief history of tweaks and improvements;\n",
    "\n",
    "Firstly, I had just one 5x5 Convolution in the beginning. I still believe that it would work okay, but because of computational reasons, I substituted this layer with two consecutive 3x3 convolution. This trick actually was introduced in a paper about VGG and it's quite intuitive because the receptive field remains the same, but a number of parameters is lower. \n",
    "\n",
    "Second, inspired by augmentation techniques presented in AlexNet paper, I did flips and random crops and finally increased the size of my training data on CIFAR10 in 3 times. I believe that augmentation played an important role and greatly enhanced performance.\n",
    "\n",
    "Third, to reduce the number of parameters and inspired by GoogLeNet paper, I did not use two fully connected layers in the end, but substituted first fully connected layer with average pooling to shrink all feature maps to the vector $ X\\in R^C$, where $C$ is the number of channels.\n",
    "\n",
    "* what is the final architecture and why?\n",
    "\n",
    "These improvements led to the final choice of the architecture, which I used further. I also experimented with the different number of channels. The pipeline of $C^3 \\rightarrow C^{256} \\rightarrow C^{256} \\rightarrow C^{512} \\rightarrow C^{1024}$ seems to be the best for the specific architecture I use.\n",
    "\n",
    "* what is the training method and, again, why?\n",
    "\n",
    "Among optimization techniques I found an Adam (surprised?) to be the best. I also experimented with SGD. It's faster but earns poorer results (surprised?). \n",
    "\n",
    "To find an appropriate number of epochs I firstly ran a network through 50 epochs and found that after 18-th one there was absolutely no improvement on a validation set. I was able to fix it by decreasing learning rate and got the number of epochs that give an enhancement to 25. Experiments with decreasing learning rate after 25-th epoch with the total number of epochs increased were not so successful. \n",
    "\n",
    "The choice of a batch size was based on the idea to find a balance between computational time and the speed of convergence. With higher batch sizes network took larger steps to an optimum, but the price was the time. I found that the batch size of 128 is a good compromise.\n",
    "\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "I tried both Dropout and Batch Normalization. First did not give any improvements and even slightly reduced an accuracy. On the other hand, Batch Normalization greatly improved the performance and turned to be crucial to build a good network.\n",
    "<br>\n",
    "<br>\n",
    "<br>\n",
    "For fine-tuning and random-initialization on CIFAR's 100 two classes. The number of epochs was chosen based on the same principle: I first run a network on the many epochs and check after which one the performance plateaus, then play with decreasing learning rates to increase the number of epochs from which we the network is able to earn something."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P.S. Cool Homework. Thanks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
